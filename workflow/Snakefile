"""
Lab Virome QC Pipeline
======================

A comprehensive quality control pipeline for VLP-enriched virome sequencing data
generated from RdAB amplification and Illumina NovaSeq sequencing.

Key Features:
- NovaSeq polyG tail removal (critical for 2-channel chemistry)
- Optical duplicate removal
- Adapter trimming (Illumina + custom primers)
- Quality filtering
- PhiX control removal
- Host genome depletion
- rRNA contamination removal
- ViromeQC enrichment assessment
- Comprehensive QC reporting with MultiQC

Author: Lab Virome QC Team
License: MIT
"""

import os
from pathlib import Path

# Configuration
configfile: "config/config.yaml"

# Sample information
SAMPLES = config["samples"]

# Output directory
OUTDIR = config["output_dir"]

# Reference paths
REFERENCES = config["references"]

# ================================================================================
# Target Rule - What we want to produce
# ================================================================================

rule all:
    input:
        # Final QC report
        f"{OUTDIR}/multiqc/multiqc_report.html",
        # ViromeQC results
        expand(f"{OUTDIR}/viromeqc/{{sample}}_viromeqc.txt", sample=SAMPLES),
        # Read count tracking
        f"{OUTDIR}/reports/read_counts.tsv",
        # Sample QC flags
        f"{OUTDIR}/reports/sample_qc_flags.tsv"

# ================================================================================
# QC Rules
# ================================================================================

rule fastqc_raw:
    """
    Run FastQC on raw reads to assess initial quality and identify artifacts
    """
    input:
        r1 = lambda wc: config["samples"][wc.sample]["r1"],
        r2 = lambda wc: config["samples"][wc.sample]["r2"]
    output:
        html_r1 = f"{OUTDIR}/fastqc/raw/{{sample}}_R1_fastqc.html",
        html_r2 = f"{OUTDIR}/fastqc/raw/{{sample}}_R2_fastqc.html",
        zip_r1 = f"{OUTDIR}/fastqc/raw/{{sample}}_R1_fastqc.zip",
        zip_r2 = f"{OUTDIR}/fastqc/raw/{{sample}}_R2_fastqc.zip"
    log:
        f"{OUTDIR}/logs/fastqc_raw/{{sample}}.log"
    threads: 2
    conda:
        "envs/qc.yaml"
    shell:
        """
        fastqc -t {threads} -o $(dirname {output.html_r1}) {input.r1} {input.r2} 2>&1 | tee {log}
        """

rule clumpify_optical_duplicates:
    """
    Remove optical duplicates using Clumpify (BBTools)
    These are Illumina sequencing artifacts from patterned flow cells
    """
    input:
        r1 = lambda wc: config["samples"][wc.sample]["r1"],
        r2 = lambda wc: config["samples"][wc.sample]["r2"]
    output:
        r1 = temp(f"{OUTDIR}/clumpify/{{sample}}_R1.fastq.gz"),
        r2 = temp(f"{OUTDIR}/clumpify/{{sample}}_R2.fastq.gz")
    log:
        f"{OUTDIR}/logs/clumpify/{{sample}}.log"
    threads: 8
    resources:
        mem_mb = 16000
    conda:
        "envs/bbtools.yaml"
    shell:
        """
        clumpify.sh \
            in1={input.r1} in2={input.r2} \
            out1={output.r1} out2={output.r2} \
            dedupe optical \
            threads={threads} \
            -Xmx{resources.mem_mb}m \
            2>&1 | tee {log}
        """

def get_fastp_input(wildcards):
    """
    Get fastp input files - either from clumpify (if enabled) or raw reads (if skipped)
    """
    if config.get("skip_clumpify", False):
        # Skip clumpify - use raw reads directly
        return {
            "r1": SAMPLES[wildcards.sample]["r1"],
            "r2": SAMPLES[wildcards.sample]["r2"]
        }
    else:
        # Use clumpify output
        return {
            "r1": f"{OUTDIR}/clumpify/{wildcards.sample}_R1.fastq.gz",
            "r2": f"{OUTDIR}/clumpify/{wildcards.sample}_R2.fastq.gz"
        }

rule fastp_trim:
    """
    CRITICAL STEP: fastp with NovaSeq-specific settings

    1. PolyG tail removal (NovaSeq 2-channel chemistry artifact) - MUST BE FIRST
    2. Adapter trimming (auto-detect Illumina adapters)
    3. Quality filtering (Q20 threshold)
    4. Length filtering (100bp minimum due to library prep artifacts)
    5. Complexity filtering

    This handles most NovaSeq + Illumina library prep artifacts

    NOTE: Input source depends on skip_clumpify config:
    - If skip_clumpify=false: Uses clumpify output (optical duplicates removed)
    - If skip_clumpify=true: Uses raw reads directly (for synthetic data or small test sets)
    """
    input:
        unpack(get_fastp_input)
    output:
        r1 = temp(f"{OUTDIR}/fastp/{{sample}}_R1.fastq.gz"),
        r2 = temp(f"{OUTDIR}/fastp/{{sample}}_R2.fastq.gz"),
        html = f"{OUTDIR}/fastp/{{sample}}_fastp.html",
        json = f"{OUTDIR}/fastp/{{sample}}_fastp.json"
    log:
        f"{OUTDIR}/logs/fastp/{{sample}}.log"
    threads: 8
    params:
        min_length = config.get("min_read_length", 100),
        qual_threshold = config.get("quality_threshold", 20)
    conda:
        "envs/qc.yaml"
    shell:
        """
        fastp \
            -i {input.r1} -I {input.r2} \
            -o {output.r1} -O {output.r2} \
            --trim_poly_g \
            --poly_g_min_len 10 \
            --detect_adapter_for_pe \
            --qualified_quality_phred {params.qual_threshold} \
            --length_required {params.min_length} \
            --low_complexity_filter \
            --complexity_threshold 30 \
            --correction \
            --thread {threads} \
            --html {output.html} \
            --json {output.json} \
            2>&1 | tee {log}
        """

rule fastqc_trimmed:
    """
    FastQC on trimmed reads to verify polyG removal and adapter trimming success
    """
    input:
        r1 = f"{OUTDIR}/fastp/{{sample}}_R1.fastq.gz",
        r2 = f"{OUTDIR}/fastp/{{sample}}_R2.fastq.gz"
    output:
        html_r1 = f"{OUTDIR}/fastqc/trimmed/{{sample}}_R1_fastqc.html",
        html_r2 = f"{OUTDIR}/fastqc/trimmed/{{sample}}_R2_fastqc.html",
        zip_r1 = f"{OUTDIR}/fastqc/trimmed/{{sample}}_R1_fastqc.zip",
        zip_r2 = f"{OUTDIR}/fastqc/trimmed/{{sample}}_R2_fastqc.zip"
    log:
        f"{OUTDIR}/logs/fastqc_trimmed/{{sample}}.log"
    threads: 2
    conda:
        "envs/qc.yaml"
    shell:
        """
        fastqc -t {threads} -o $(dirname {output.html_r1}) {input.r1} {input.r2} 2>&1 | tee {log}
        """

rule remove_phix:
    """
    Remove PhiX174 control sequences using BBDuk (k-mer based)
    PhiX is commonly spiked into Illumina runs as internal control
    """
    input:
        r1 = f"{OUTDIR}/fastp/{{sample}}_R1.fastq.gz",
        r2 = f"{OUTDIR}/fastp/{{sample}}_R2.fastq.gz"
    output:
        r1 = temp(f"{OUTDIR}/phix_removed/{{sample}}_R1.fastq.gz"),
        r2 = temp(f"{OUTDIR}/phix_removed/{{sample}}_R2.fastq.gz"),
        stats = f"{OUTDIR}/phix_removed/{{sample}}_phix_stats.txt"
    log:
        f"{OUTDIR}/logs/phix_removal/{{sample}}.log"
    threads: 4
    resources:
        mem_mb = 8000
    params:
        phix_ref = REFERENCES["phix"]
    conda:
        "envs/bbtools.yaml"
    shell:
        """
        bbduk.sh \
            in1={input.r1} in2={input.r2} \
            out1={output.r1} out2={output.r2} \
            ref={params.phix_ref} \
            k=31 hdist=1 \
            stats={output.stats} \
            threads={threads} \
            -Xmx{resources.mem_mb}m \
            2>&1 | tee {log}
        """

rule host_depletion:
    """
    Remove host genome sequences using minimap2

    For VLP-enriched samples, high host contamination (>10%) indicates VLP prep failure
    This step serves dual purpose:
    1. Remove host sequences from analysis
    2. QC metric for VLP enrichment success
    """
    input:
        r1 = f"{OUTDIR}/phix_removed/{{sample}}_R1.fastq.gz",
        r2 = f"{OUTDIR}/phix_removed/{{sample}}_R2.fastq.gz",
        host_ref = REFERENCES["host_genome"]
    output:
        r1 = temp(f"{OUTDIR}/host_depleted/{{sample}}_R1.fastq.gz"),
        r2 = temp(f"{OUTDIR}/host_depleted/{{sample}}_R2.fastq.gz"),
        stats = f"{OUTDIR}/host_depleted/{{sample}}_host_stats.txt"
    log:
        f"{OUTDIR}/logs/host_depletion/{{sample}}.log"
    threads: 8
    resources:
        mem_mb = 16000
    conda:
        "envs/mapping.yaml"
    shell:
        """
        # Map to host genome
        minimap2 -ax sr -t {threads} {input.host_ref} {input.r1} {input.r2} 2>> {log} | \
        samtools view -@ {threads} -bS - | \
        samtools sort -@ {threads} -n -o - | \
        samtools fastq -@ {threads} -f 12 -F 256 \
            -1 {output.r1} -2 {output.r2} - 2>> {log}

        # Calculate host mapping stats
        echo "Sample: {wildcards.sample}" > {output.stats}
        echo "Host reference: {input.host_ref}" >> {output.stats}
        minimap2 -ax sr -t {threads} {input.host_ref} {input.r1} {input.r2} 2>> {log} | \
        samtools view -@ {threads} -c >> {output.stats}
        """

rule remove_rrna:
    """
    Remove ribosomal RNA sequences using BBDuk

    Uses SILVA database for comprehensive rRNA removal
    Critical for RT-based protocols where all RNA gets converted to cDNA
    """
    input:
        r1 = f"{OUTDIR}/host_depleted/{{sample}}_R1.fastq.gz",
        r2 = f"{OUTDIR}/host_depleted/{{sample}}_R2.fastq.gz"
    output:
        r1 = temp(f"{OUTDIR}/rrna_removed/{{sample}}_R1.fastq.gz"),
        r2 = temp(f"{OUTDIR}/rrna_removed/{{sample}}_R2.fastq.gz"),
        stats = f"{OUTDIR}/rrna_removed/{{sample}}_rrna_stats.txt"
    log:
        f"{OUTDIR}/logs/rrna_removal/{{sample}}.log"
    threads: 4
    resources:
        mem_mb = 8000
    params:
        rrna_ref = REFERENCES["rrna"]
    conda:
        "envs/bbtools.yaml"
    shell:
        """
        bbduk.sh \
            in1={input.r1} in2={input.r2} \
            out1={output.r1} out2={output.r2} \
            ref={params.rrna_ref} \
            k=31 \
            stats={output.stats} \
            threads={threads} \
            -Xmx{resources.mem_mb}m \
            2>&1 | tee {log}
        """

rule viromeqc:
    """
    ViromeQC: THE critical QC metric for VLP-enriched viromes

    Calculates enrichment score based on:
    - SSU rRNA gene abundance
    - LSU rRNA gene abundance
    - 31 prokaryotic single-copy marker genes

    Low enrichment score = VLP prep failure or excessive bacterial contamination
    """
    input:
        r1 = f"{OUTDIR}/rrna_removed/{{sample}}_R1.fastq.gz",
        r2 = f"{OUTDIR}/rrna_removed/{{sample}}_R2.fastq.gz"
    output:
        report = f"{OUTDIR}/viromeqc/{{sample}}_viromeqc.txt"
    log:
        f"{OUTDIR}/logs/viromeqc/{{sample}}.log"
    threads: 4
    conda:
        "envs/viromeqc.yaml"
    shell:
        """
        viromeQC.py \
            -i {input.r1} {input.r2} \
            -o {output.report} \
            2>&1 | tee {log}
        """

rule final_fastqc:
    """
    Final FastQC on clean reads
    """
    input:
        r1 = f"{OUTDIR}/rrna_removed/{{sample}}_R1.fastq.gz",
        r2 = f"{OUTDIR}/rrna_removed/{{sample}}_R2.fastq.gz"
    output:
        html_r1 = f"{OUTDIR}/fastqc/final/{{sample}}_R1_fastqc.html",
        html_r2 = f"{OUTDIR}/fastqc/final/{{sample}}_R2_fastqc.html",
        zip_r1 = f"{OUTDIR}/fastqc/final/{{sample}}_R1_fastqc.zip",
        zip_r2 = f"{OUTDIR}/fastqc/final/{{sample}}_R2_fastqc.zip"
    log:
        f"{OUTDIR}/logs/fastqc_final/{{sample}}.log"
    threads: 2
    conda:
        "envs/qc.yaml"
    shell:
        """
        fastqc -t {threads} -o $(dirname {output.html_r1}) {input.r1} {input.r2} 2>&1 | tee {log}
        """

rule symlink_clean_reads:
    """
    Create symlinks to final clean reads for easy access
    """
    input:
        r1 = f"{OUTDIR}/rrna_removed/{{sample}}_R1.fastq.gz",
        r2 = f"{OUTDIR}/rrna_removed/{{sample}}_R2.fastq.gz"
    output:
        r1 = f"{OUTDIR}/clean_reads/{{sample}}_R1_clean.fastq.gz",
        r2 = f"{OUTDIR}/clean_reads/{{sample}}_R2_clean.fastq.gz"
    shell:
        """
        ln -sf $(readlink -f {input.r1}) {output.r1}
        ln -sf $(readlink -f {input.r2}) {output.r2}
        """

# ================================================================================
# Reporting Rules
# ================================================================================

def get_count_reads_input(wildcards):
    """
    Get count_reads input files - conditionally include clumpify output if not skipped
    """
    inputs = {
        "raw_r1": SAMPLES[wildcards.sample]["r1"],
        "fastp_r1": f"{OUTDIR}/fastp/{wildcards.sample}_R1.fastq.gz",
        "phix_r1": f"{OUTDIR}/phix_removed/{wildcards.sample}_R1.fastq.gz",
        "host_r1": f"{OUTDIR}/host_depleted/{wildcards.sample}_R1.fastq.gz",
        "rrna_r1": f"{OUTDIR}/rrna_removed/{wildcards.sample}_R1.fastq.gz"
    }
    if not config.get("skip_clumpify", False):
        inputs["clumpify_r1"] = f"{OUTDIR}/clumpify/{wildcards.sample}_R1.fastq.gz"
    return inputs

rule count_reads:
    """
    Count reads at each QC step for tracking
    NOTE: Clumpify step only counted if skip_clumpify=false
    """
    input:
        unpack(get_count_reads_input)
    output:
        temp(f"{OUTDIR}/reports/read_counts/{{sample}}.tsv")
    params:
        skip_clumpify = config.get("skip_clumpify", False)
    conda:
        "envs/qc.yaml"
    shell:
        """
        echo -e "sample\tstep\treads" > {output}
        echo -e "{wildcards.sample}\traw\t$(zcat {input.raw_r1} | wc -l | awk '{{print $1/4}}')" >> {output}
        if [ "{params.skip_clumpify}" = "False" ]; then
            echo -e "{wildcards.sample}\tclumpify\t$(zcat {input.clumpify_r1} | wc -l | awk '{{print $1/4}}')" >> {output}
        fi
        echo -e "{wildcards.sample}\tfastp\t$(zcat {input.fastp_r1} | wc -l | awk '{{print $1/4}}')" >> {output}
        echo -e "{wildcards.sample}\tphix_removed\t$(zcat {input.phix_r1} | wc -l | awk '{{print $1/4}}')" >> {output}
        echo -e "{wildcards.sample}\thost_depleted\t$(zcat {input.host_r1} | wc -l | awk '{{print $1/4}}')" >> {output}
        echo -e "{wildcards.sample}\tclean\t$(zcat {input.rrna_r1} | wc -l | awk '{{print $1/4}}')" >> {output}
        """

rule merge_read_counts:
    """
    Merge read counts from all samples
    """
    input:
        expand(f"{OUTDIR}/reports/read_counts/{{sample}}.tsv", sample=SAMPLES)
    output:
        f"{OUTDIR}/reports/read_counts.tsv"
    shell:
        """
        head -n 1 {input[0]} > {output}
        tail -n +2 -q {input} >> {output}
        """

rule qc_flags:
    """
    Generate QC pass/fail flags for each sample based on:
    - ViromeQC enrichment score
    - % host reads
    - % rRNA reads
    - Final read count
    """
    input:
        viromeqc = expand(f"{OUTDIR}/viromeqc/{{sample}}_viromeqc.txt", sample=SAMPLES),
        read_counts = f"{OUTDIR}/reports/read_counts.tsv"
    output:
        f"{OUTDIR}/reports/sample_qc_flags.tsv"
    conda:
        "envs/qc.yaml"
    script:
        "scripts/generate_qc_flags.py"

rule multiqc:
    """
    Aggregate all QC reports into single MultiQC dashboard
    """
    input:
        # FastQC reports
        expand(f"{OUTDIR}/fastqc/raw/{{sample}}_R1_fastqc.zip", sample=SAMPLES),
        expand(f"{OUTDIR}/fastqc/trimmed/{{sample}}_R1_fastqc.zip", sample=SAMPLES),
        expand(f"{OUTDIR}/fastqc/final/{{sample}}_R1_fastqc.zip", sample=SAMPLES),
        # fastp reports
        expand(f"{OUTDIR}/fastp/{{sample}}_fastp.json", sample=SAMPLES),
        # ViromeQC
        expand(f"{OUTDIR}/viromeqc/{{sample}}_viromeqc.txt", sample=SAMPLES),
        # Read counts
        f"{OUTDIR}/reports/read_counts.tsv",
        # QC flags
        f"{OUTDIR}/reports/sample_qc_flags.tsv"
    output:
        f"{OUTDIR}/multiqc/multiqc_report.html"
    log:
        f"{OUTDIR}/logs/multiqc.log"
    conda:
        "envs/qc.yaml"
    shell:
        """
        multiqc \
            {OUTDIR} \
            -o {OUTDIR}/multiqc \
            -n multiqc_report.html \
            --force \
            2>&1 | tee {log}
        """
