"""
Lab Virome QC Pipeline
======================

A comprehensive quality control pipeline for VLP-enriched virome sequencing data
generated from RdAB amplification and Illumina NovaSeq sequencing.

Key Features:
- NovaSeq polyG tail removal (critical for 2-channel chemistry)
- Optical duplicate removal
- Adapter trimming (Illumina + custom primers)
- Quality filtering
- PhiX control removal
- Host genome depletion
- rRNA contamination removal
- ViromeQC enrichment assessment
- Comprehensive QC reporting with MultiQC

Author: Lab Virome QC Team
License: MIT
"""

import os
import sys
from pathlib import Path

# Add scripts directory to Python path
workflow_dir = Path(workflow.basedir)
scripts_dir = workflow_dir / "scripts"
sys.path.insert(0, str(scripts_dir))

from sample_utils import get_samples

# Configuration
configfile: "config/config.yaml"

# Sample information - auto-detect or use manual config
SAMPLES = get_samples(config)

# Output directory
OUTDIR = config["output_dir"]

# Reference paths
REFERENCES = config["references"]

# ================================================================================
# Target Rule - What we want to produce
# ================================================================================

rule all:
    input:
        # Final QC report
        f"{OUTDIR}/multiqc/multiqc_report.html",
        # ViromeQC results
        expand(f"{OUTDIR}/viromeqc/{{sample}}_viromeqc.txt", sample=SAMPLES),
        # Read count tracking
        f"{OUTDIR}/reports/read_counts.tsv",
        # Sample QC flags
        f"{OUTDIR}/reports/sample_qc_flags.tsv",
        # Contamination flagging summary
        f"{OUTDIR}/reports/contamination_summary.tsv",
        # Contamination plots
        f"{OUTDIR}/reports/contamination_bars.png",
        f"{OUTDIR}/reports/contamination_boxes.png",
        f"{OUTDIR}/reports/contamination_scatter.png",
        f"{OUTDIR}/reports/contamination_heatmap.png",
        # Primer B cross-contamination analysis
        f"{OUTDIR}/reports/primer_b_contamination_summary.tsv",
        f"{OUTDIR}/reports/primer_b_heatmap.png"

# ================================================================================
# QC Rules
# ================================================================================

rule fastqc_raw:
    """
    Run FastQC on raw reads to assess initial quality and identify artifacts
    """
    input:
        r1 = lambda wc: SAMPLES[wc.sample]["r1"],
        r2 = lambda wc: SAMPLES[wc.sample]["r2"]
    output:
        html_r1 = f"{OUTDIR}/fastqc/raw/{{sample}}_R1_fastqc.html",
        html_r2 = f"{OUTDIR}/fastqc/raw/{{sample}}_R2_fastqc.html",
        zip_r1 = f"{OUTDIR}/fastqc/raw/{{sample}}_R1_fastqc.zip",
        zip_r2 = f"{OUTDIR}/fastqc/raw/{{sample}}_R2_fastqc.zip"
    log:
        f"{OUTDIR}/logs/fastqc_raw/{{sample}}.log"
    threads: 2
    conda:
        "envs/qc.yaml"
    shell:
        """
        fastqc -t {threads} -o $(dirname {output.html_r1}) {input.r1} {input.r2} 2>&1 | tee {log}
        """

rule clumpify_optical_duplicates:
    """
    Remove optical duplicates using Clumpify (BBTools)
    These are Illumina sequencing artifacts from patterned flow cells

    Note: Memory requirement scales with read count (~0.5GB per million reads)
          Allocated 48GB to handle samples up to ~95 million reads
    """
    input:
        r1 = lambda wc: SAMPLES[wc.sample]["r1"],
        r2 = lambda wc: SAMPLES[wc.sample]["r2"]
    output:
        r1 = temp(f"{OUTDIR}/clumpify/{{sample}}_R1.fastq.gz"),
        r2 = temp(f"{OUTDIR}/clumpify/{{sample}}_R2.fastq.gz")
    log:
        f"{OUTDIR}/logs/clumpify/{{sample}}.log"
    threads: 8
    resources:
        mem_mb = 48000
    conda:
        "envs/bbtools.yaml"
    shell:
        """
        clumpify.sh \
            in1={input.r1} in2={input.r2} \
            out1={output.r1} out2={output.r2} \
            dedupe optical \
            threads={threads} \
            -Xmx{resources.mem_mb}m \
            2>&1 | tee {log}
        """

rule fastp_trim:
    """
    CRITICAL STEP: fastp with NovaSeq-specific settings

    1. PolyG tail removal (NovaSeq 2-channel chemistry artifact) - MUST BE FIRST
    2. Adapter trimming (auto-detect Illumina adapters)
    3. Quality filtering (Q20 threshold)
    4. Length filtering (100bp minimum due to library prep artifacts)
    5. Complexity filtering

    This handles most NovaSeq + Illumina library prep artifacts
    """
    input:
        r1 = f"{OUTDIR}/clumpify/{{sample}}_R1.fastq.gz",
        r2 = f"{OUTDIR}/clumpify/{{sample}}_R2.fastq.gz"
    output:
        r1 = temp(f"{OUTDIR}/fastp/{{sample}}_R1.fastq.gz"),
        r2 = temp(f"{OUTDIR}/fastp/{{sample}}_R2.fastq.gz"),
        html = f"{OUTDIR}/fastp/{{sample}}_fastp.html",
        json = f"{OUTDIR}/fastp/{{sample}}_fastp.json"
    log:
        f"{OUTDIR}/logs/fastp/{{sample}}.log"
    threads: 8
    params:
        min_length = config.get("min_read_length", 100),
        qual_threshold = config.get("quality_threshold", 20)
    conda:
        "envs/qc.yaml"
    shell:
        """
        fastp \
            -i {input.r1} -I {input.r2} \
            -o {output.r1} -O {output.r2} \
            --trim_poly_g \
            --poly_g_min_len 10 \
            --detect_adapter_for_pe \
            --qualified_quality_phred {params.qual_threshold} \
            --length_required {params.min_length} \
            --low_complexity_filter \
            --complexity_threshold 30 \
            --correction \
            --thread {threads} \
            --html {output.html} \
            --json {output.json} \
            2>&1 | tee {log}
        """

rule fastqc_trimmed:
    """
    FastQC on trimmed reads to verify polyG removal and adapter trimming success
    """
    input:
        r1 = f"{OUTDIR}/fastp/{{sample}}_R1.fastq.gz",
        r2 = f"{OUTDIR}/fastp/{{sample}}_R2.fastq.gz"
    output:
        html_r1 = f"{OUTDIR}/fastqc/trimmed/{{sample}}_R1_fastqc.html",
        html_r2 = f"{OUTDIR}/fastqc/trimmed/{{sample}}_R2_fastqc.html",
        zip_r1 = f"{OUTDIR}/fastqc/trimmed/{{sample}}_R1_fastqc.zip",
        zip_r2 = f"{OUTDIR}/fastqc/trimmed/{{sample}}_R2_fastqc.zip"
    log:
        f"{OUTDIR}/logs/fastqc_trimmed/{{sample}}.log"
    threads: 2
    conda:
        "envs/qc.yaml"
    shell:
        """
        fastqc -t {threads} -o $(dirname {output.html_r1}) {input.r1} {input.r2} 2>&1 | tee {log}
        """

rule remove_primer_b_forward:
    """
    Remove forward primer B sequences using left-side trimming

    Step 1 of 2-step primer B removal process. Removes forward primer B sequences
    that may contaminate the 5' end of reads. Each sample should have primarily one
    primer B variant; presence of multiple variants indicates cross-contamination.

    This step generates stats for downstream cross-contamination analysis.
    """
    input:
        r1 = f"{OUTDIR}/fastp/{{sample}}_R1.fastq.gz",
        r2 = f"{OUTDIR}/fastp/{{sample}}_R2.fastq.gz"
    output:
        r1 = temp(f"{OUTDIR}/primer_b/step1/{{sample}}_R1.fastq.gz"),
        r2 = temp(f"{OUTDIR}/primer_b/step1/{{sample}}_R2.fastq.gz"),
        stats = f"{OUTDIR}/primer_b/stats/step1/{{sample}}_pb_fwd_stats.txt"
    log:
        f"{OUTDIR}/logs/primer_b/{{sample}}_step1.log"
    threads: 4
    resources:
        mem_mb = 8000
    params:
        ref = REFERENCES["primer_b_forward"],
        ktrim = config["primer_b"]["bbduk_forward"]["ktrim"],
        k = config["primer_b"]["bbduk_forward"]["k"],
        mink = config["primer_b"]["bbduk_forward"]["mink"],
        rcomp = config["primer_b"]["bbduk_forward"]["rcomp"],
        ordered = config["primer_b"]["bbduk_forward"]["ordered"],
        ow = config["primer_b"]["bbduk_forward"]["ow"]
    conda:
        "envs/bbtools.yaml"
    shell:
        """
        bbduk.sh \
            in1={input.r1} in2={input.r2} \
            out1={output.r1} out2={output.r2} \
            ref={params.ref} \
            stats={output.stats} \
            ktrim={params.ktrim} \
            k={params.k} \
            mink={params.mink} \
            rcomp={params.rcomp} \
            ordered={params.ordered} \
            ow={params.ow} \
            threads={threads} \
            -Xmx{resources.mem_mb}m \
            2>&1 | tee {log}
        """

rule remove_primer_b_rc:
    """
    Remove reverse complement primer B sequences using right-side trimming

    Step 2 of 2-step primer B removal process. Removes reverse complement primer B
    sequences that may contaminate the 3' end of reads after step 1.

    This step generates stats for downstream cross-contamination analysis.
    """
    input:
        r1 = f"{OUTDIR}/primer_b/step1/{{sample}}_R1.fastq.gz",
        r2 = f"{OUTDIR}/primer_b/step1/{{sample}}_R2.fastq.gz"
    output:
        r1 = temp(f"{OUTDIR}/primer_b/step2/{{sample}}_R1.fastq.gz"),
        r2 = temp(f"{OUTDIR}/primer_b/step2/{{sample}}_R2.fastq.gz"),
        stats = f"{OUTDIR}/primer_b/stats/step2/{{sample}}_pb_rc_stats.txt"
    log:
        f"{OUTDIR}/logs/primer_b/{{sample}}_step2.log"
    threads: 4
    resources:
        mem_mb = 8000
    params:
        ref = REFERENCES["primer_b_rc"],
        ktrim = config["primer_b"]["bbduk_rc"]["ktrim"],
        k = config["primer_b"]["bbduk_rc"]["k"],
        mink = config["primer_b"]["bbduk_rc"]["mink"],
        rcomp = config["primer_b"]["bbduk_rc"]["rcomp"],
        ordered = config["primer_b"]["bbduk_rc"]["ordered"],
        ow = config["primer_b"]["bbduk_rc"]["ow"]
    conda:
        "envs/bbtools.yaml"
    shell:
        """
        bbduk.sh \
            in1={input.r1} in2={input.r2} \
            out1={output.r1} out2={output.r2} \
            ref={params.ref} \
            stats={output.stats} \
            ktrim={params.ktrim} \
            k={params.k} \
            mink={params.mink} \
            rcomp={params.rcomp} \
            ordered={params.ordered} \
            ow={params.ow} \
            threads={threads} \
            -Xmx{resources.mem_mb}m \
            2>&1 | tee {log}
        """

rule flag_phix:
    """
    Flag PhiX174 contamination without removing reads

    For VLP-enriched viromes, we flag contamination rather than remove it to avoid
    accidentally discarding legitimate viral sequences. This generates QC metrics
    to identify samples with abnormal PhiX levels (which may indicate sequencing issues).

    Uses BBDuk in detection-only mode to quantify PhiX contamination.

    Note: Runs on primer B-removed reads to avoid false positives from primer sequences.
    """
    input:
        r1 = f"{OUTDIR}/primer_b/step2/{{sample}}_R1.fastq.gz",
        r2 = f"{OUTDIR}/primer_b/step2/{{sample}}_R2.fastq.gz"
    output:
        stats = f"{OUTDIR}/contamination_flagging/phix/{{sample}}_phix_stats.txt"
    log:
        f"{OUTDIR}/logs/flag_phix/{{sample}}.log"
    threads: 4
    resources:
        mem_mb = 8000
    params:
        phix_ref = REFERENCES["phix"]
    conda:
        "envs/bbtools.yaml"
    shell:
        """
        # Run bbduk in stats-only mode (no read filtering)
        # Redirect stdout to /dev/null since we only want stats
        bbduk.sh \
            in1={input.r1} in2={input.r2} \
            ref={params.phix_ref} \
            k=31 hdist=1 \
            stats={output.stats} \
            threads={threads} \
            -Xmx{resources.mem_mb}m \
            2>&1 | tee {log}
        """

rule flag_univec:
    """
    Flag vector/plasmid contamination without removing reads

    Checks for common cloning vectors, plasmids, and synthetic sequences that may
    indicate laboratory contamination. Generates QC metrics to identify outlier samples.

    Uses comprehensive UniVec-derived database including common lab vectors.

    Note: Runs on primer B-removed reads to avoid false positives from primer sequences.
    """
    input:
        r1 = f"{OUTDIR}/primer_b/step2/{{sample}}_R1.fastq.gz",
        r2 = f"{OUTDIR}/primer_b/step2/{{sample}}_R2.fastq.gz"
    output:
        stats = f"{OUTDIR}/contamination_flagging/univec/{{sample}}_univec_stats.txt"
    log:
        f"{OUTDIR}/logs/flag_univec/{{sample}}.log"
    threads: 4
    resources:
        mem_mb = 8000
    params:
        vector_ref = REFERENCES["vector_contaminants"]
    conda:
        "envs/bbtools.yaml"
    shell:
        """
        # Run bbduk in stats-only mode to detect vector contamination
        bbduk.sh \
            in1={input.r1} in2={input.r2} \
            ref={params.vector_ref} \
            k=31 hdist=1 \
            stats={output.stats} \
            threads={threads} \
            -Xmx{resources.mem_mb}m \
            2>&1 | tee {log}
        """

rule host_depletion:
    """
    Remove host genome sequences using minimap2

    For VLP-enriched samples, high host contamination (>10%) indicates VLP prep failure
    This step serves dual purpose:
    1. Remove host sequences from analysis
    2. QC metric for VLP enrichment success

    Note: Operates on primer B-removed reads (PhiX/vector flagging doesn't filter reads)
    Note: Minimap2 loads host genome index (~12GB for human) plus read processing
          Allocated 24GB to handle large samples
    """
    input:
        r1 = f"{OUTDIR}/primer_b/step2/{{sample}}_R1.fastq.gz",
        r2 = f"{OUTDIR}/primer_b/step2/{{sample}}_R2.fastq.gz",
        host_ref = REFERENCES["host_genome"],
        # Ensure contamination flagging happens first (for workflow ordering)
        phix_stats = f"{OUTDIR}/contamination_flagging/phix/{{sample}}_phix_stats.txt",
        univec_stats = f"{OUTDIR}/contamination_flagging/univec/{{sample}}_univec_stats.txt"
    output:
        r1 = temp(f"{OUTDIR}/host_depleted/{{sample}}_R1.fastq.gz"),
        r2 = temp(f"{OUTDIR}/host_depleted/{{sample}}_R2.fastq.gz"),
        stats = f"{OUTDIR}/host_depleted/{{sample}}_host_stats.txt"
    log:
        f"{OUTDIR}/logs/host_depletion/{{sample}}.log"
    threads: 8
    resources:
        mem_mb = 24000
    conda:
        "envs/mapping.yaml"
    shell:
        """
        # Map to host genome
        minimap2 -ax sr -t {threads} {input.host_ref} {input.r1} {input.r2} 2>> {log} | \
        samtools view -@ {threads} -bS - | \
        samtools sort -@ {threads} -n -o - | \
        samtools fastq -@ {threads} -f 12 -F 256 \
            -1 {output.r1} -2 {output.r2} - 2>> {log}

        # Calculate host mapping stats
        echo "Sample: {wildcards.sample}" > {output.stats}
        echo "Host reference: {input.host_ref}" >> {output.stats}
        minimap2 -ax sr -t {threads} {input.host_ref} {input.r1} {input.r2} 2>> {log} | \
        samtools view -@ {threads} -c >> {output.stats}
        """

rule remove_rrna:
    """
    Remove ribosomal RNA sequences using BBDuk

    Uses SILVA database for comprehensive rRNA removal
    Critical for RT-based protocols where all RNA gets converted to cDNA

    Note: Full SILVA SSU+LSU database loads 123M kmers (~5GB)
          Additional memory needed for read processing on large samples
          Allocated 32GB to handle database + up to 95M reads
    """
    input:
        r1 = f"{OUTDIR}/host_depleted/{{sample}}_R1.fastq.gz",
        r2 = f"{OUTDIR}/host_depleted/{{sample}}_R2.fastq.gz"
    output:
        r1 = temp(f"{OUTDIR}/rrna_removed/{{sample}}_R1.fastq.gz"),
        r2 = temp(f"{OUTDIR}/rrna_removed/{{sample}}_R2.fastq.gz"),
        stats = f"{OUTDIR}/rrna_removed/{{sample}}_rrna_stats.txt"
    log:
        f"{OUTDIR}/logs/rrna_removal/{{sample}}.log"
    threads: 4
    resources:
        mem_mb = 32000
    params:
        rrna_ref = REFERENCES["rrna"]
    conda:
        "envs/bbtools.yaml"
    shell:
        """
        bbduk.sh \
            in1={input.r1} in2={input.r2} \
            out1={output.r1} out2={output.r2} \
            ref={params.rrna_ref} \
            k=31 \
            stats={output.stats} \
            threads={threads} \
            -Xmx{resources.mem_mb}m \
            2>&1 | tee {log}
        """

rule remove_pcr_duplicates:
    """
    Remove PCR duplicates using dedupe.sh from BBTools

    For Round A/B virome data with 40 cycles of PCR, this step removes massive
    PCR duplication (typically 80-90%+ of reads), getting closer to "unique
    molecules present" rather than "PCR-amplified copies."

    Placement rationale:
    - Last QC step (after all quality filtering and rRNA removal)
    - Quality filtering has already removed error-containing reads
    - More accurate duplicate detection on clean viral reads
    - Prevents keeping "wrong" copies with sequencing errors

    Optional: Controlled by config['deduplication']['pcr']['enabled']
    - Enable for high-cycle PCR data (Round A/B with 40 cycles)
    - Disable for non-PCR or low-cycle data

    Note: ac=f uses sequence similarity for duplicate detection
          (appropriate for error-containing reads from high-cycle PCR)
    """
    input:
        r1 = f"{OUTDIR}/rrna_removed/{{sample}}_R1.fastq.gz",
        r2 = f"{OUTDIR}/rrna_removed/{{sample}}_R2.fastq.gz"
    output:
        r1 = temp(f"{OUTDIR}/pcr_deduplicated/{{sample}}_R1.fastq.gz"),
        r2 = temp(f"{OUTDIR}/pcr_deduplicated/{{sample}}_R2.fastq.gz"),
        stats = f"{OUTDIR}/pcr_deduplicated/{{sample}}_pcr_dup_stats.txt"
    log:
        f"{OUTDIR}/logs/pcr_deduplication/{{sample}}.log"
    threads: 8
    resources:
        mem_mb = 32000  # Similar to rRNA removal, scales with read count
    conda:
        "envs/bbtools.yaml"
    shell:
        """
        dedupe.sh \
            in1={input.r1} in2={input.r2} \
            out1={output.r1} out2={output.r2} \
            ac=f \
            threads={threads} \
            -Xmx{resources.mem_mb}m \
            2>&1 | tee {log}

        # Extract stats for reporting
        # dedupe.sh outputs stats to stderr/stdout, captured in log
        grep -E "^(Input|Duplicates|Result)" {log} > {output.stats} || true
        """

rule viromeqc:
    """
    ViromeQC: THE critical QC metric for VLP-enriched viromes

    Calculates enrichment score based on:
    - SSU rRNA gene abundance
    - LSU rRNA gene abundance
    - 31 prokaryotic single-copy marker genes

    Low enrichment score = VLP prep failure or excessive bacterial contamination

    IMPORTANT: Runs on host_depleted reads (BEFORE rRNA removal) to get accurate
    enrichment scores. Running after rRNA removal would artificially inflate the
    enrichment score since rRNA has already been removed.

    Note: Runs bowtie2 and diamond alignments which require memory for large samples
          Allocated 16GB to handle samples up to ~95M reads
          Can take several hours for large samples (>10M reads)
    """
    input:
        r1 = f"{OUTDIR}/host_depleted/{{sample}}_R1.fastq.gz",
        r2 = f"{OUTDIR}/host_depleted/{{sample}}_R2.fastq.gz"
    output:
        report = f"{OUTDIR}/viromeqc/{{sample}}_viromeqc.txt"
    log:
        f"{OUTDIR}/logs/viromeqc/{{sample}}.log"
    threads: 4
    resources:
        mem_mb = 16000,
        time_min = 720
    conda:
        "envs/viromeqc.yaml"
    shell:
        """
        viromeQC.py \
            -i {input.r1} {input.r2} \
            -o {output.report} \
            2>&1 | tee {log}
        """

rule final_fastqc:
    """
    Final FastQC on clean reads

    Input depends on PCR deduplication setting:
    - If PCR dedup enabled: uses pcr_deduplicated reads
    - If PCR dedup disabled: uses rrna_removed reads
    """
    input:
        r1 = lambda wc: f"{OUTDIR}/pcr_deduplicated/{wc.sample}_R1.fastq.gz" if config.get("deduplication", {}).get("pcr", {}).get("enabled", False) else f"{OUTDIR}/rrna_removed/{wc.sample}_R1.fastq.gz",
        r2 = lambda wc: f"{OUTDIR}/pcr_deduplicated/{wc.sample}_R2.fastq.gz" if config.get("deduplication", {}).get("pcr", {}).get("enabled", False) else f"{OUTDIR}/rrna_removed/{wc.sample}_R2.fastq.gz"
    output:
        html_r1 = f"{OUTDIR}/fastqc/final/{{sample}}_R1_fastqc.html",
        html_r2 = f"{OUTDIR}/fastqc/final/{{sample}}_R2_fastqc.html",
        zip_r1 = f"{OUTDIR}/fastqc/final/{{sample}}_R1_fastqc.zip",
        zip_r2 = f"{OUTDIR}/fastqc/final/{{sample}}_R2_fastqc.zip"
    log:
        f"{OUTDIR}/logs/fastqc_final/{{sample}}.log"
    threads: 2
    conda:
        "envs/qc.yaml"
    shell:
        """
        fastqc -t {threads} -o $(dirname {output.html_r1}) {input.r1} {input.r2} 2>&1 | tee {log}
        """

rule symlink_clean_reads:
    """
    Create symlinks to final clean reads for easy access

    Input depends on PCR deduplication setting:
    - If PCR dedup enabled: uses pcr_deduplicated reads
    - If PCR dedup disabled: uses rrna_removed reads
    """
    input:
        r1 = lambda wc: f"{OUTDIR}/pcr_deduplicated/{wc.sample}_R1.fastq.gz" if config.get("deduplication", {}).get("pcr", {}).get("enabled", False) else f"{OUTDIR}/rrna_removed/{wc.sample}_R1.fastq.gz",
        r2 = lambda wc: f"{OUTDIR}/pcr_deduplicated/{wc.sample}_R2.fastq.gz" if config.get("deduplication", {}).get("pcr", {}).get("enabled", False) else f"{OUTDIR}/rrna_removed/{wc.sample}_R2.fastq.gz"
    output:
        r1 = f"{OUTDIR}/clean_reads/{{sample}}_R1_clean.fastq.gz",
        r2 = f"{OUTDIR}/clean_reads/{{sample}}_R2_clean.fastq.gz"
    shell:
        """
        ln -sf $(readlink -f {input.r1}) {output.r1}
        ln -sf $(readlink -f {input.r2}) {output.r2}
        """

# ================================================================================
# Reporting Rules
# ================================================================================

rule count_reads:
    """
    Count reads at each QC step for tracking

    Tracks reads through the full pipeline including primer B removal
    Note: phix_removed step removed since we now flag instead of filter
    Note: Conditionally includes pcr_deduplicated step if enabled
    Note: Can take several hours for large samples (50M+ reads)
    """
    input:
        raw_r1 = lambda wc: SAMPLES[wc.sample]["r1"],
        clumpify_r1 = f"{OUTDIR}/clumpify/{{sample}}_R1.fastq.gz",
        fastp_r1 = f"{OUTDIR}/fastp/{{sample}}_R1.fastq.gz",
        pb_step1_r1 = f"{OUTDIR}/primer_b/step1/{{sample}}_R1.fastq.gz",
        pb_step2_r1 = f"{OUTDIR}/primer_b/step2/{{sample}}_R1.fastq.gz",
        host_r1 = f"{OUTDIR}/host_depleted/{{sample}}_R1.fastq.gz",
        rrna_r1 = f"{OUTDIR}/rrna_removed/{{sample}}_R1.fastq.gz",
        pcr_dedup_r1 = lambda wc: f"{OUTDIR}/pcr_deduplicated/{wc.sample}_R1.fastq.gz" if config.get("deduplication", {}).get("pcr", {}).get("enabled", False) else []
    output:
        temp(f"{OUTDIR}/reports/read_counts/{{sample}}.tsv")
    resources:
        time_min = 360
    params:
        pcr_dedup_enabled = config.get("deduplication", {}).get("pcr", {}).get("enabled", False)
    conda:
        "envs/qc.yaml"
    shell:
        """
        echo -e "sample\tstep\treads" > {output}
        echo -e "{wildcards.sample}\traw\t$(zcat {input.raw_r1} | wc -l | awk '{{print $1/4}}')" >> {output}
        echo -e "{wildcards.sample}\tclumpify\t$(zcat {input.clumpify_r1} | wc -l | awk '{{print $1/4}}')" >> {output}
        echo -e "{wildcards.sample}\tfastp\t$(zcat {input.fastp_r1} | wc -l | awk '{{print $1/4}}')" >> {output}
        echo -e "{wildcards.sample}\tprimer_b_fwd\t$(zcat {input.pb_step1_r1} | wc -l | awk '{{print $1/4}}')" >> {output}
        echo -e "{wildcards.sample}\tprimer_b_rc\t$(zcat {input.pb_step2_r1} | wc -l | awk '{{print $1/4}}')" >> {output}
        echo -e "{wildcards.sample}\thost_depleted\t$(zcat {input.host_r1} | wc -l | awk '{{print $1/4}}')" >> {output}
        echo -e "{wildcards.sample}\trrna_removed\t$(zcat {input.rrna_r1} | wc -l | awk '{{print $1/4}}')" >> {output}

        # Conditionally add PCR dedup stats
        if [ "{params.pcr_dedup_enabled}" = "True" ]; then
            echo -e "{wildcards.sample}\tclean\t$(zcat {input.pcr_dedup_r1} | wc -l | awk '{{print $1/4}}')" >> {output}
        else
            echo -e "{wildcards.sample}\tclean\t$(zcat {input.rrna_r1} | wc -l | awk '{{print $1/4}}')" >> {output}
        fi
        """

rule merge_read_counts:
    """
    Merge read counts from all samples
    """
    input:
        expand(f"{OUTDIR}/reports/read_counts/{{sample}}.tsv", sample=SAMPLES)
    output:
        f"{OUTDIR}/reports/read_counts.tsv"
    shell:
        """
        head -n 1 {input[0]} > {output}
        tail -n +2 -q {input} >> {output}
        """

rule aggregate_contamination_stats:
    """
    Aggregate PhiX and vector contamination statistics across all samples

    Parses BBDuk stats files to create a summary table showing contamination
    levels per sample. This helps identify outlier samples with abnormal
    contamination that may indicate sequencing or library prep issues.
    """
    input:
        phix_stats = expand(f"{OUTDIR}/contamination_flagging/phix/{{sample}}_phix_stats.txt", sample=SAMPLES),
        univec_stats = expand(f"{OUTDIR}/contamination_flagging/univec/{{sample}}_univec_stats.txt", sample=SAMPLES)
    output:
        f"{OUTDIR}/reports/contamination_summary.tsv"
    conda:
        "envs/qc.yaml"
    script:
        "scripts/aggregate_contamination_stats.py"

rule plot_contamination:
    """
    Generate contamination visualization plots

    Creates multiple plot types to help identify outlier samples:
    - Bar plot: contamination levels per sample
    - Box plot: distribution of contamination levels
    - Scatter plot: correlation between PhiX and vector contamination
    - Heatmap: overview of contamination across all samples
    """
    input:
        f"{OUTDIR}/reports/contamination_summary.tsv"
    output:
        f"{OUTDIR}/reports/contamination_bars.png",
        f"{OUTDIR}/reports/contamination_boxes.png",
        f"{OUTDIR}/reports/contamination_scatter.png",
        f"{OUTDIR}/reports/contamination_heatmap.png"
    params:
        output_prefix = f"{OUTDIR}/reports/contamination"
    conda:
        "envs/qc.yaml"
    script:
        "scripts/plot_contamination.py"

rule analyze_primer_b_contamination:
    """
    Analyze primer B cross-contamination across all samples

    Parses BBDuk stats from primer B removal steps to detect cross-contamination.
    Each sample should have primarily one primer B variant; multiple variants
    indicate cross-contamination during library prep or sequencing.

    Outputs:
    - Summary table with dominant primer B and contamination metrics
    - Distribution data for heatmap visualization
    """
    input:
        step1 = expand(f"{OUTDIR}/primer_b/stats/step1/{{sample}}_pb_fwd_stats.txt", sample=SAMPLES),
        step2 = expand(f"{OUTDIR}/primer_b/stats/step2/{{sample}}_pb_rc_stats.txt", sample=SAMPLES)
    output:
        summary = f"{OUTDIR}/reports/primer_b_contamination_summary.tsv",
        distribution = f"{OUTDIR}/reports/primer_b_distribution.tsv"
    params:
        sample_assignments = config["primer_b"].get("sample_assignments", None),
        contamination_threshold = config["primer_b"]["contamination_threshold"]
    conda:
        "envs/qc.yaml"
    script:
        "scripts/analyze_primer_b_contamination.py"

rule plot_primer_b_heatmap:
    """
    Generate primer B cross-contamination heatmap

    Creates a heatmap showing primer B variant distribution across samples.
    Helps identify cross-contamination patterns and verify sample identity.
    """
    input:
        distribution = f"{OUTDIR}/reports/primer_b_distribution.tsv",
        summary = f"{OUTDIR}/reports/primer_b_contamination_summary.tsv"
    output:
        heatmap = f"{OUTDIR}/reports/primer_b_heatmap.png"
    conda:
        "envs/qc.yaml"
    script:
        "scripts/plot_primer_b_heatmap.py"

rule qc_flags:
    """
    Generate QC pass/fail flags for each sample based on:
    - ViromeQC enrichment score
    - % host reads
    - % rRNA reads
    - Final read count
    """
    input:
        viromeqc = expand(f"{OUTDIR}/viromeqc/{{sample}}_viromeqc.txt", sample=SAMPLES),
        read_counts = f"{OUTDIR}/reports/read_counts.tsv"
    output:
        f"{OUTDIR}/reports/sample_qc_flags.tsv"
    conda:
        "envs/qc.yaml"
    script:
        "scripts/generate_qc_flags.py"

rule multiqc:
    """
    Aggregate all QC reports into single MultiQC dashboard

    Now includes contamination flagging summary
    """
    input:
        # FastQC reports
        expand(f"{OUTDIR}/fastqc/raw/{{sample}}_R1_fastqc.zip", sample=SAMPLES),
        expand(f"{OUTDIR}/fastqc/trimmed/{{sample}}_R1_fastqc.zip", sample=SAMPLES),
        expand(f"{OUTDIR}/fastqc/final/{{sample}}_R1_fastqc.zip", sample=SAMPLES),
        # fastp reports
        expand(f"{OUTDIR}/fastp/{{sample}}_fastp.json", sample=SAMPLES),
        # ViromeQC
        expand(f"{OUTDIR}/viromeqc/{{sample}}_viromeqc.txt", sample=SAMPLES),
        # Read counts
        f"{OUTDIR}/reports/read_counts.tsv",
        # QC flags
        f"{OUTDIR}/reports/sample_qc_flags.tsv",
        # Contamination summary
        f"{OUTDIR}/reports/contamination_summary.tsv"
    output:
        f"{OUTDIR}/multiqc/multiqc_report.html"
    log:
        f"{OUTDIR}/logs/multiqc.log"
    conda:
        "envs/qc.yaml"
    shell:
        """
        multiqc \
            {OUTDIR} \
            -o {OUTDIR}/multiqc \
            -n multiqc_report.html \
            --force \
            2>&1 | tee {log}
        """
